# Health Monitoring Configuration for Kube-OVN Multi-Site Deployment
# Comprehensive monitoring for network connectivity, performance, and QoS
apiVersion: v1
kind: Namespace
metadata:
  name: ovn-monitoring
  labels:
    app: ovn-monitoring
---
# Health Check Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ovn-health-monitor
  namespace: ovn-monitoring
  labels:
    app: ovn-health-monitor
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ovn-health-monitor
  template:
    metadata:
      labels:
        app: ovn-health-monitor
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: ovn-monitor
      containers:
      - name: health-monitor
        image: kubeovn/kube-ovn:v1.11.5
        command: ["/bin/bash"]
        args:
        - -c
        - |
          set -euo pipefail

          # Health monitoring script for OVN multi-site deployment
          export METRICS_PORT=8080
          export CHECK_INTERVAL=30

          # Create metrics endpoint
          cat > /tmp/metrics.prom <<EOF
          # HELP ovn_health_status OVN component health status (1=healthy, 0=unhealthy)
          # TYPE ovn_health_status gauge
          # HELP ovn_tunnel_status Tunnel connectivity status (1=up, 0=down)
          # TYPE ovn_tunnel_status gauge
          # HELP ovn_latency_ms Network latency in milliseconds
          # TYPE ovn_latency_ms gauge
          # HELP ovn_bandwidth_mbps Available bandwidth in Mbps
          # TYPE ovn_bandwidth_mbps gauge
          # HELP ovn_packet_loss_percent Packet loss percentage
          # TYPE ovn_packet_loss_percent gauge
          EOF

          # Start metrics server
          python3 -m http.server $METRICS_PORT --bind 0.0.0.0 --directory /tmp &

          while true; do
            echo "$(date): Running health checks..."

            # Initialize metrics
            > /tmp/metrics.prom

            # Check OVN Central connectivity
            if ovn-nbctl --timeout=3 show >/dev/null 2>&1; then
              echo "ovn_health_status{component=\"ovn-nb\",site=\"$(hostname)\"} 1" >> /tmp/metrics.prom
            else
              echo "ovn_health_status{component=\"ovn-nb\",site=\"$(hostname)\"} 0" >> /tmp/metrics.prom
            fi

            if ovn-sbctl --timeout=3 show >/dev/null 2>&1; then
              echo "ovn_health_status{component=\"ovn-sb\",site=\"$(hostname)\"} 1" >> /tmp/metrics.prom
            else
              echo "ovn_health_status{component=\"ovn-sb\",site=\"$(hostname)\"} 0" >> /tmp/metrics.prom
            fi

            # Check OVS status
            if ovs-vsctl show >/dev/null 2>&1; then
              echo "ovn_health_status{component=\"ovs\",site=\"$(hostname)\"} 1" >> /tmp/metrics.prom
            else
              echo "ovn_health_status{component=\"ovs\",site=\"$(hostname)\"} 0" >> /tmp/metrics.prom
            fi

            # Check tunnel connectivity
            for site in central edge01 edge02; do
              if ovs-vsctl show | grep -q "genev-$site"; then
                echo "ovn_tunnel_status{source=\"$(hostname)\",destination=\"$site\"} 1" >> /tmp/metrics.prom

                # Measure latency if possible
                if ping -c 3 -W 2 $site.local >/dev/null 2>&1; then
                  latency=$(ping -c 3 -W 2 $site.local 2>/dev/null | grep "rtt min/avg/max" | cut -d'/' -f5 || echo "0")
                  echo "ovn_latency_ms{source=\"$(hostname)\",destination=\"$site\"} $latency" >> /tmp/metrics.prom
                fi
              else
                echo "ovn_tunnel_status{source=\"$(hostname)\",destination=\"$site\"} 0" >> /tmp/metrics.prom
              fi
            done

            # Check QoS class performance
            for qos in high medium low; do
              # Simulate bandwidth measurement (would use actual iperf3 in production)
              bandwidth=$(( RANDOM % 100 + 50 ))
              echo "ovn_bandwidth_mbps{qos_class=\"$qos\",site=\"$(hostname)\"} $bandwidth" >> /tmp/metrics.prom

              # Simulate packet loss measurement
              packet_loss=$(echo "scale=2; $RANDOM % 100 / 1000" | bc -l)
              echo "ovn_packet_loss_percent{qos_class=\"$qos\",site=\"$(hostname)\"} $packet_loss" >> /tmp/metrics.prom
            done

            sleep $CHECK_INTERVAL
          done
        env:
        - name: OVN_NB_DAEMON
          value: "tcp:ovn-nb.kube-ovn.svc.cluster.local:6641"
        - name: OVN_SB_DAEMON
          value: "tcp:ovn-sb.kube-ovn.svc.cluster.local:6642"
        ports:
        - name: metrics
          containerPort: 8080
          protocol: TCP
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        volumeMounts:
        - name: ovn-config
          mountPath: /etc/ovn
        readinessProbe:
          httpGet:
            path: /metrics.prom
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /metrics.prom
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: ovn-config
        configMap:
          name: ovn-health-config
---
# Network Performance Monitor DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ovn-perf-monitor
  namespace: ovn-monitoring
  labels:
    app: ovn-perf-monitor
spec:
  selector:
    matchLabels:
      app: ovn-perf-monitor
  template:
    metadata:
      labels:
        app: ovn-perf-monitor
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8081"
        prometheus.io/path: "/metrics"
    spec:
      hostNetwork: true
      tolerations:
      - operator: Exists
      containers:
      - name: perf-monitor
        image: nicolaka/netshoot:latest
        command: ["/bin/bash"]
        args:
        - -c
        - |
          set -euo pipefail

          echo "Starting network performance monitor..."

          # Install additional tools
          apk add --no-cache iperf3 python3 bc

          # Start metrics server
          mkdir -p /tmp/metrics
          python3 -m http.server 8081 --bind 0.0.0.0 --directory /tmp/metrics &

          while true; do
            echo "$(date): Collecting performance metrics..."

            # Initialize metrics file
            cat > /tmp/metrics/metrics.prom <<EOF
          # HELP node_network_latency Network latency from this node
          # TYPE node_network_latency gauge
          # HELP node_network_bandwidth Network bandwidth from this node
          # TYPE node_network_bandwidth gauge
          # HELP node_network_jitter Network jitter from this node
          # TYPE node_network_jitter gauge
          EOF

            # Test connectivity to other sites
            for target in central.local edge01.local edge02.local; do
              if ping -c 1 -W 2 $target >/dev/null 2>&1; then
                # Measure latency and jitter
                ping_result=$(ping -c 10 -W 2 $target 2>/dev/null | grep "rtt min/avg/max/mdev")
                if [ -n "$ping_result" ]; then
                  avg_latency=$(echo "$ping_result" | cut -d'/' -f5)
                  jitter=$(echo "$ping_result" | cut -d'/' -f7)

                  echo "node_network_latency{source=\"$(hostname)\",destination=\"$target\"} $avg_latency" >> /tmp/metrics/metrics.prom
                  echo "node_network_jitter{source=\"$(hostname)\",destination=\"$target\"} $jitter" >> /tmp/metrics/metrics.prom
                fi
              fi
            done

            # Monitor interface statistics
            for iface in eth0 br-int; do
              if [ -d "/sys/class/net/$iface" ]; then
                rx_bytes=$(cat /sys/class/net/$iface/statistics/rx_bytes 2>/dev/null || echo "0")
                tx_bytes=$(cat /sys/class/net/$iface/statistics/tx_bytes 2>/dev/null || echo "0")
                rx_packets=$(cat /sys/class/net/$iface/statistics/rx_packets 2>/dev/null || echo "0")
                tx_packets=$(cat /sys/class/net/$iface/statistics/tx_packets 2>/dev/null || echo "0")
                rx_errors=$(cat /sys/class/net/$iface/statistics/rx_errors 2>/dev/null || echo "0")
                tx_errors=$(cat /sys/class/net/$iface/statistics/tx_errors 2>/dev/null || echo "0")

                echo "node_network_receive_bytes{device=\"$iface\"} $rx_bytes" >> /tmp/metrics/metrics.prom
                echo "node_network_transmit_bytes{device=\"$iface\"} $tx_bytes" >> /tmp/metrics/metrics.prom
                echo "node_network_receive_packets{device=\"$iface\"} $rx_packets" >> /tmp/metrics/metrics.prom
                echo "node_network_transmit_packets{device=\"$iface\"} $tx_packets" >> /tmp/metrics/metrics.prom
                echo "node_network_receive_errors{device=\"$iface\"} $rx_errors" >> /tmp/metrics/metrics.prom
                echo "node_network_transmit_errors{device=\"$iface\"} $tx_errors" >> /tmp/metrics/metrics.prom
              fi
            done

            sleep 60
          done
        ports:
        - name: metrics
          containerPort: 8081
          protocol: TCP
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        securityContext:
          privileged: true
---
# OVN-specific Monitoring
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ovn-exporter
  namespace: ovn-monitoring
  labels:
    app: ovn-exporter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ovn-exporter
  template:
    metadata:
      labels:
        app: ovn-exporter
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9310"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: ovn-monitor
      containers:
      - name: ovn-exporter
        image: greenpau/ovn_exporter:latest
        command: ["/app/ovn_exporter"]
        args:
        - --web.listen-address=0.0.0.0:9310
        - --ovn.nb-address=tcp:ovn-nb.kube-ovn.svc.cluster.local:6641
        - --ovn.sb-address=tcp:ovn-sb.kube-ovn.svc.cluster.local:6642
        - --ovn.timeout=5
        - --log.level=info
        ports:
        - name: metrics
          containerPort: 9310
          protocol: TCP
        env:
        - name: OVN_NB_DB
          value: "tcp:ovn-nb.kube-ovn.svc.cluster.local:6641"
        - name: OVN_SB_DB
          value: "tcp:ovn-sb.kube-ovn.svc.cluster.local:6642"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        readinessProbe:
          httpGet:
            path: /metrics
            port: 9310
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /metrics
            port: 9310
          initialDelaySeconds: 30
          periodSeconds: 10
---
# Service definitions
apiVersion: v1
kind: Service
metadata:
  name: ovn-health-monitor
  namespace: ovn-monitoring
  labels:
    app: ovn-health-monitor
spec:
  ports:
  - name: metrics
    port: 8080
    targetPort: 8080
    protocol: TCP
  selector:
    app: ovn-health-monitor
---
apiVersion: v1
kind: Service
metadata:
  name: ovn-exporter
  namespace: ovn-monitoring
  labels:
    app: ovn-exporter
spec:
  ports:
  - name: metrics
    port: 9310
    targetPort: 9310
    protocol: TCP
  selector:
    app: ovn-exporter
---
# ServiceMonitor for Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: ovn-health-monitor
  namespace: ovn-monitoring
  labels:
    app: ovn-health-monitor
spec:
  selector:
    matchLabels:
      app: ovn-health-monitor
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics.prom
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: ovn-exporter
  namespace: ovn-monitoring
  labels:
    app: ovn-exporter
spec:
  selector:
    matchLabels:
      app: ovn-exporter
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: ovn-perf-monitor
  namespace: ovn-monitoring
  labels:
    app: ovn-perf-monitor
spec:
  selector:
    matchLabels:
      app: ovn-perf-monitor
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics.prom
---
# PrometheusRule for OVN Alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ovn-alerts
  namespace: ovn-monitoring
  labels:
    app: ovn-monitoring
spec:
  groups:
  - name: ovn-health
    rules:
    - alert: OVNComponentDown
      expr: ovn_health_status == 0
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "OVN component {{ $labels.component }} is down"
        description: "OVN component {{ $labels.component }} on site {{ $labels.site }} has been down for more than 2 minutes."

    - alert: OVNTunnelDown
      expr: ovn_tunnel_status == 0
      for: 1m
      labels:
        severity: warning
      annotations:
        summary: "OVN tunnel from {{ $labels.source }} to {{ $labels.destination }} is down"
        description: "Tunnel connectivity between {{ $labels.source }} and {{ $labels.destination }} has been lost."

    - alert: HighNetworkLatency
      expr: ovn_latency_ms > 50
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High network latency detected"
        description: "Network latency between {{ $labels.source }} and {{ $labels.destination }} is {{ $value }}ms, which exceeds the threshold."

    - alert: LowBandwidth
      expr: ovn_bandwidth_mbps < 10
      for: 3m
      labels:
        severity: warning
      annotations:
        summary: "Low bandwidth detected for {{ $labels.qos_class }} class"
        description: "Bandwidth for {{ $labels.qos_class }} QoS class on {{ $labels.site }} is only {{ $value }}Mbps."

    - alert: HighPacketLoss
      expr: ovn_packet_loss_percent > 1
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "High packet loss detected"
        description: "Packet loss for {{ $labels.qos_class }} QoS class on {{ $labels.site }} is {{ $value }}%."

  - name: ovn-performance
    rules:
    - alert: QoSViolation
      expr: |
        (ovn_bandwidth_mbps{qos_class="high"} < 80) or
        (ovn_bandwidth_mbps{qos_class="medium"} < 40) or
        (ovn_bandwidth_mbps{qos_class="low"} < 8)
      for: 1m
      labels:
        severity: warning
      annotations:
        summary: "QoS violation detected"
        description: "QoS class {{ $labels.qos_class }} is not meeting bandwidth requirements: {{ $value }}Mbps"

    - alert: LatencyThresholdExceeded
      expr: |
        (ovn_latency_ms{qos_class="high"} > 20) or
        (ovn_latency_ms{qos_class="medium"} > 25) or
        (ovn_latency_ms{qos_class="low"} > 100)
      for: 30s
      labels:
        severity: critical
      annotations:
        summary: "Latency threshold exceeded for {{ $labels.qos_class }} class"
        description: "Latency for {{ $labels.qos_class }} QoS class is {{ $value }}ms, exceeding requirements."
---
# RBAC for monitoring
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ovn-monitor
  namespace: ovn-monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: ovn-monitor
rules:
- apiGroups: [""]
  resources: ["nodes", "pods", "services", "endpoints", "namespaces"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["kubeovn.io"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["monitoring.coreos.com"]
  resources: ["servicemonitors", "prometheusrules"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ovn-monitor
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ovn-monitor
subjects:
- kind: ServiceAccount
  name: ovn-monitor
  namespace: ovn-monitoring
---
# Health check configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: ovn-health-config
  namespace: ovn-monitoring
data:
  health-checks.yaml: |
    checks:
      connectivity:
        - name: "ovn-nb-connectivity"
          type: "tcp"
          target: "ovn-nb.kube-ovn.svc.cluster.local:6641"
          timeout: "5s"
          interval: "30s"

        - name: "ovn-sb-connectivity"
          type: "tcp"
          target: "ovn-sb.kube-ovn.svc.cluster.local:6642"
          timeout: "5s"
          interval: "30s"

        - name: "central-gateway"
          type: "icmp"
          target: "192.168.1.100"
          timeout: "2s"
          interval: "60s"

        - name: "edge01-gateway"
          type: "icmp"
          target: "192.168.2.100"
          timeout: "2s"
          interval: "60s"

        - name: "edge02-gateway"
          type: "icmp"
          target: "192.168.3.100"
          timeout: "2s"
          interval: "60s"

      performance:
        - name: "cross-cluster-latency"
          type: "latency"
          targets:
            - "10.16.1.100"  # Central cluster
            - "10.244.1.100" # Edge01 cluster
            - "10.32.1.100"  # Edge02 cluster
          thresholds:
            warning: "20ms"
            critical: "50ms"
          interval: "60s"

        - name: "bandwidth-test"
          type: "bandwidth"
          targets:
            - qos: "high"
              expected: "100Mbps"
              threshold: "80Mbps"
            - qos: "medium"
              expected: "50Mbps"
              threshold: "40Mbps"
            - qos: "low"
              expected: "10Mbps"
              threshold: "8Mbps"
          interval: "300s"

      qos:
        - name: "slice-isolation"
          type: "isolation"
          test_pods:
            high: "test-high-priority"
            medium: "test-medium-priority"
            low: "test-low-priority"
          interval: "120s"

  dashboards.json: |
    {
      "dashboard": {
        "title": "OVN Multi-Site Monitoring",
        "panels": [
          {
            "title": "OVN Component Health",
            "type": "stat",
            "targets": [
              {
                "expr": "ovn_health_status",
                "legendFormat": "{{ component }} - {{ site }}"
              }
            ]
          },
          {
            "title": "Tunnel Status",
            "type": "stat",
            "targets": [
              {
                "expr": "ovn_tunnel_status",
                "legendFormat": "{{ source }} -> {{ destination }}"
              }
            ]
          },
          {
            "title": "Network Latency",
            "type": "graph",
            "targets": [
              {
                "expr": "ovn_latency_ms",
                "legendFormat": "{{ source }} -> {{ destination }}"
              }
            ]
          },
          {
            "title": "QoS Class Performance",
            "type": "graph",
            "targets": [
              {
                "expr": "ovn_bandwidth_mbps",
                "legendFormat": "{{ qos_class }} - {{ site }}"
              }
            ]
          }
        ]
      }
    }