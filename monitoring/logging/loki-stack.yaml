---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: loki
  namespace: oran-monitoring
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/component: logging
    app.kubernetes.io/part-of: oran-intent-mano
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: oran-monitoring
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: oran-intent-mano
data:
  loki.yaml: |
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9096
      grpc_server_max_recv_msg_size: 8388608
      grpc_server_max_send_msg_size: 8388608

    common:
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory

    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb_shipper:
        active_index_directory: /loki/boltdb-shipper-active
        cache_location: /loki/boltdb-shipper-cache
        cache_ttl: 24h
        shared_store: filesystem
      filesystem:
        directory: /loki/chunks

    compactor:
      working_directory: /loki/boltdb-shipper-compactor
      shared_store: filesystem

    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      ingestion_rate_mb: 16
      ingestion_burst_size_mb: 24
      max_concurrent_tail_requests: 20
      max_cache_freshness_per_query: 10m

    chunk_store_config:
      max_look_back_period: 0s

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s

    ruler:
      storage:
        type: local
        local:
          directory: /loki/rules
      rule_path: /loki/rules
      alertmanager_url: http://alertmanager:9093
      ring:
        kvstore:
          store: inmemory
      enable_api: true
      enable_alertmanager_v2: true

    frontend:
      compress_responses: true
      max_outstanding_per_tenant: 256
      log_queries_longer_than: 5s

    query_range:
      align_queries_with_step: true
      max_retries: 5
      cache_results: true
      results_cache:
        cache:
          embedded_cache:
            enabled: true
            max_size_mb: 100

    analytics:
      reporting_enabled: false

  # O-RAN specific log parsing rules
  rules.yaml: |
    groups:
    - name: oran-log-alerts
      rules:
      - alert: ORanHighErrorLogRate
        expr: |
          (
            sum(rate({namespace=~"oran-.*"} |~ "(?i)error|exception|fail" [5m])) by (namespace)
            /
            sum(rate({namespace=~"oran-.*"}[5m])) by (namespace)
          ) > 0.05
        for: 2m
        labels:
          severity: warning
          component: logging
        annotations:
          summary: "High error rate in O-RAN component logs"
          description: "Error rate is {{ $value | humanizePercentage }} in namespace {{ $labels.namespace }}"

      - alert: ORanCriticalLogMessages
        expr: sum(rate({namespace=~"oran-.*"} |~ "(?i)critical|fatal|panic" [5m])) > 0
        for: 0m
        labels:
          severity: critical
          component: logging
        annotations:
          summary: "Critical log messages detected"
          description: "{{ $value }} critical log messages per second detected in O-RAN components"

      - alert: ORanSliceDeploymentErrors
        expr: sum(rate({namespace="oran-orchestrator"} |~ "slice.*deploy.*(?i)error|fail" [5m])) > 0
        for: 1m
        labels:
          severity: critical
          component: orchestrator
          thesis_target: deployment
        annotations:
          summary: "Slice deployment errors detected"
          description: "{{ $value }} slice deployment errors per second in orchestrator logs"

      - alert: ORanIntentProcessingErrors
        expr: sum(rate({namespace="oran-nlp"} |~ "intent.*process.*(?i)error|fail" [5m])) > 0
        for: 1m
        labels:
          severity: warning
          component: nlp
          thesis_target: intent_processing
        annotations:
          summary: "Intent processing errors detected"
          description: "{{ $value }} intent processing errors per second in NLP service logs"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: oran-monitoring
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/component: logging
    app.kubernetes.io/part-of: oran-intent-mano
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: loki
  template:
    metadata:
      labels:
        app.kubernetes.io/name: loki
        app.kubernetes.io/component: logging
        app.kubernetes.io/part-of: oran-intent-mano
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "3100"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: loki
      securityContext:
        runAsNonRoot: true
        runAsUser: 10001
        runAsGroup: 10001
        fsGroup: 10001
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: loki
        image: grafana/loki:2.9.2
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 10001
          runAsGroup: 10001
        args:
        - -config.file=/etc/loki/loki.yaml
        - -target=all
        ports:
        - containerPort: 3100
          name: http-metrics
          protocol: TCP
        - containerPort: 9096
          name: grpc
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
          periodSeconds: 10
          timeoutSeconds: 1
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 45
          periodSeconds: 10
          timeoutSeconds: 1
          failureThreshold: 3
        resources:
          limits:
            cpu: 1000m
            memory: 2Gi
          requests:
            cpu: 100m
            memory: 256Mi
        volumeMounts:
        - name: loki-config
          mountPath: /etc/loki
        - name: loki-storage
          mountPath: /loki
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: loki-config
        configMap:
          name: loki-config
      - name: loki-storage
        persistentVolumeClaim:
          claimName: loki-storage
      - name: tmp
        emptyDir: {}
      nodeSelector:
        kubernetes.io/os: linux
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: oran-monitoring
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/component: logging
    app.kubernetes.io/part-of: oran-intent-mano
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "3100"
spec:
  type: ClusterIP
  ports:
  - name: http-metrics
    port: 3100
    targetPort: http-metrics
    protocol: TCP
  - name: grpc
    port: 9096
    targetPort: grpc
    protocol: TCP
  selector:
    app.kubernetes.io/name: loki
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: loki-storage
  namespace: oran-monitoring
  labels:
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: oran-intent-mano
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: default
---
# Promtail DaemonSet for log collection
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: oran-monitoring
  labels:
    app.kubernetes.io/name: promtail
    app.kubernetes.io/part-of: oran-intent-mano
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
  labels:
    app.kubernetes.io/name: promtail
    app.kubernetes.io/part-of: oran-intent-mano
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
  labels:
    app.kubernetes.io/name: promtail
    app.kubernetes.io/part-of: oran-intent-mano
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail
subjects:
- kind: ServiceAccount
  name: promtail
  namespace: oran-monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: oran-monitoring
  labels:
    app.kubernetes.io/name: promtail
    app.kubernetes.io/part-of: oran-intent-mano
data:
  config.yml: |
    server:
      http_listen_port: 3101
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://loki:3100/loki/api/v1/push

    scrape_configs:
    # Kubernetes pod logs
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
        - role: pod
      pipeline_stages:
        - cri: {}
      relabel_configs:
        - source_labels:
            - __meta_kubernetes_pod_controller_name
          regex: ([0-9a-z-.]+?)(-[0-9a-f]{8,10})?
          action: replace
          target_label: __tmp_controller_name
        - source_labels:
            - __meta_kubernetes_pod_label_app_kubernetes_io_name
            - __meta_kubernetes_pod_label_app
            - __tmp_controller_name
            - __meta_kubernetes_pod_name
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: app
        - source_labels:
            - __meta_kubernetes_pod_label_app_kubernetes_io_instance
            - __meta_kubernetes_pod_label_release
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: instance
        - source_labels:
            - __meta_kubernetes_pod_label_app_kubernetes_io_component
            - __meta_kubernetes_pod_label_component
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: component
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_node_name
          target_label: node_name
        - action: replace
          source_labels:
          - __meta_kubernetes_namespace
          target_label: namespace
        - action: replace
          replacement: $1
          separator: /
          source_labels:
          - namespace
          - app
          target_label: job
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_name
          target_label: pod
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_container_name
          target_label: container
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_uid
          target_label: pod_uid
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_label_app_kubernetes_io_version
          target_label: version
        - replacement: /var/log/pods/*$1/*.log
          separator: /
          source_labels:
          - __meta_kubernetes_pod_uid
          - __meta_kubernetes_pod_container_name
          target_label: __path__
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_container_id
          regex: ^(\w+)://(.*)
          replacement: $2
          target_label: container_id

    # O-RAN specific log processing
    - job_name: oran-intent-processing
      kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - oran-nlp
      pipeline_stages:
        - cri: {}
        - regex:
            expression: '.*intent_id=(?P<intent_id>[^\\s]+).*'
        - labels:
            intent_id:
        - regex:
            expression: '.*user_id=(?P<user_id>[^\\s]+).*'
        - labels:
            user_id:
        - regex:
            expression: '.*processing_time=(?P<processing_time>[0-9.]+).*'
        - labels:
            processing_time:

    - job_name: oran-slice-deployment
      kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - oran-orchestrator
      pipeline_stages:
        - cri: {}
        - regex:
            expression: '.*slice_id=(?P<slice_id>[^\\s]+).*'
        - labels:
            slice_id:
        - regex:
            expression: '.*deployment_status=(?P<deployment_status>[^\\s]+).*'
        - labels:
            deployment_status:
        - regex:
            expression: '.*deployment_time=(?P<deployment_time>[0-9.]+).*'
        - labels:
            deployment_time:

    - job_name: oran-vnf-lifecycle
      kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - oran-ran
            - oran-cn
            - oran-tn
      pipeline_stages:
        - cri: {}
        - regex:
            expression: '.*vnf_id=(?P<vnf_id>[^\\s]+).*'
        - labels:
            vnf_id:
        - regex:
            expression: '.*vnf_type=(?P<vnf_type>[^\\s]+).*'
        - labels:
            vnf_type:
        - regex:
            expression: '.*lifecycle_event=(?P<lifecycle_event>[^\\s]+).*'
        - labels:
            lifecycle_event:

    # System logs
    - job_name: kubernetes-system-logs
      static_configs:
        - targets:
            - localhost
          labels:
            job: systemd-journal
            __path__: /var/log/journal/*/*
      pipeline_stages:
        - journal:
            max_age: 12h
            labels:
              unit: __systemd_unit
              hostname: __hostname

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: oran-monitoring
  labels:
    app.kubernetes.io/name: promtail
    app.kubernetes.io/component: logging
    app.kubernetes.io/part-of: oran-intent-mano
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: promtail
  template:
    metadata:
      labels:
        app.kubernetes.io/name: promtail
        app.kubernetes.io/component: logging
        app.kubernetes.io/part-of: oran-intent-mano
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "3101"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: promtail
      securityContext:
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: promtail
        image: grafana/promtail:2.9.2
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
            add:
            - DAC_READ_SEARCH
          readOnlyRootFilesystem: true
          runAsUser: 0
        args:
        - -config.file=/etc/promtail/config.yml
        - -client.url=http://loki:3100/loki/api/v1/push
        env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        ports:
        - containerPort: 3101
          name: http-metrics
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /ready
            port: http-metrics
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 1
          failureThreshold: 5
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - name: promtail-config
          mountPath: /etc/promtail
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: varlogpods
          mountPath: /var/log/pods
          readOnly: true
        - name: run
          mountPath: /run/promtail
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: promtail-config
        configMap:
          name: promtail-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: varlogpods
        hostPath:
          path: /var/log/pods
      - name: run
        hostPath:
          path: /run/promtail
          type: DirectoryOrCreate
      - name: tmp
        emptyDir: {}
      tolerations:
      - effect: NoSchedule
        operator: Exists
      - effect: NoExecute
        operator: Exists
      nodeSelector:
        kubernetes.io/os: linux