package testutils

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/onsi/ginkgo/v2/reporters"
	"github.com/onsi/ginkgo/v2/types"

	"github.com/thc1006/O-RAN-Intent-MANO-for-Network-Slicing/pkg/security"
)

// TestReporter provides comprehensive test reporting capabilities
type TestReporter struct {
	StartTime   time.Time
	Results     []TestResult
	Summary     TestSummary
	OutputDir   string
	JUnitPath   string
	JSONPath    string
	HTMLPath    string
	CoveragePath string
}

// TestResult represents the result of a single test
type TestResult struct {
	Name        string                 `json:"name"`
	Category    string                 `json:"category"`
	Status      string                 `json:"status"`
	Duration    time.Duration          `json:"duration"`
	Error       string                 `json:"error,omitempty"`
	StartTime   time.Time              `json:"start_time"`
	EndTime     time.Time              `json:"end_time"`
	Metadata    map[string]interface{} `json:"metadata,omitempty"`
	Performance *PerformanceMetrics    `json:"performance,omitempty"`
}

// TestSummary provides an overview of test execution
type TestSummary struct {
	TotalTests      int                    `json:"total_tests"`
	PassedTests     int                    `json:"passed_tests"`
	FailedTests     int                    `json:"failed_tests"`
	SkippedTests    int                    `json:"skipped_tests"`
	Duration        time.Duration          `json:"duration"`
	StartTime       time.Time              `json:"start_time"`
	EndTime         time.Time              `json:"end_time"`
	Coverage        float64                `json:"coverage"`
	SuccessRate     float64                `json:"success_rate"`
	Categories      map[string]int         `json:"categories"`
	Performance     *PerformanceMetrics    `json:"performance,omitempty"`
	Thresholds      map[string]interface{} `json:"thresholds"`
	ThresholdsMet   bool                   `json:"thresholds_met"`
}

// PerformanceMetrics tracks performance-related metrics
type PerformanceMetrics struct {
	DeploymentTime    time.Duration `json:"deployment_time"`
	ThroughputMbps    float64       `json:"throughput_mbps"`
	LatencyMs         float64       `json:"latency_ms"`
	CPUUsage          float64       `json:"cpu_usage"`
	MemoryUsageMB     float64       `json:"memory_usage_mb"`
	ErrorRate         float64       `json:"error_rate"`
	ResponseTime99p   time.Duration `json:"response_time_99p"`
	ConcurrentUsers   int           `json:"concurrent_users"`
	RequestsPerSecond float64       `json:"requests_per_second"`
}

// NewTestReporter creates a new test reporter
func NewTestReporter() *TestReporter {
	outputDir := filepath.Join(".", "test-results")
	os.MkdirAll(outputDir, security.PrivateDirMode)

	return &TestReporter{
		StartTime:    time.Now(),
		Results:      make([]TestResult, 0),
		OutputDir:    outputDir,
		JUnitPath:    filepath.Join(outputDir, "junit.xml"),
		JSONPath:     filepath.Join(outputDir, "results.json"),
		HTMLPath:     filepath.Join(outputDir, "report.html"),
		CoveragePath: filepath.Join(outputDir, "coverage.html"),
		Summary: TestSummary{
			Categories: make(map[string]int),
			Thresholds: map[string]interface{}{
				"coverage_threshold":      90.0,
				"success_rate_threshold":  95.0,
				"max_deployment_time_s":   600, // 10 minutes
				"min_throughput_mbps":     0.9, // Thesis target for lowest QoS
				"max_latency_ms":          20.0, // Thesis target
			},
		},
	}
}

// ReportTestStart reports the start of a test
func (tr *TestReporter) ReportTestStart(testName string) {
	fmt.Printf("üöÄ Starting test: %s\n", testName)
}

// ReportTestResult reports the result of a test
func (tr *TestReporter) ReportTestResult(result TestResult) {
	tr.Results = append(tr.Results, result)
	tr.Summary.TotalTests++

	switch result.Status {
	case "passed":
		tr.Summary.PassedTests++
		fmt.Printf("‚úÖ PASS: %s (%v)\n", result.Name, result.Duration)
	case "failed":
		tr.Summary.FailedTests++
		fmt.Printf("‚ùå FAIL: %s (%v) - %s\n", result.Name, result.Duration, result.Error)
	case "skipped":
		tr.Summary.SkippedTests++
		fmt.Printf("‚è≠Ô∏è  SKIP: %s\n", result.Name)
	}

	tr.Summary.Categories[result.Category]++
}

// GenerateReports generates all test reports
func (tr *TestReporter) GenerateReports() error {
	tr.Summary.EndTime = time.Now()
	tr.Summary.Duration = tr.Summary.EndTime.Sub(tr.StartTime)

	if tr.Summary.TotalTests > 0 {
		tr.Summary.SuccessRate = float64(tr.Summary.PassedTests) / float64(tr.Summary.TotalTests) * 100
	}

	// Check if thresholds are met
	tr.checkThresholds()

	// Generate JSON report
	if err := tr.generateJSONReport(); err != nil {
		return fmt.Errorf("failed to generate JSON report: %w", err)
	}

	// Generate JUnit XML report
	if err := tr.generateJUnitReport(); err != nil {
		return fmt.Errorf("failed to generate JUnit report: %w", err)
	}

	// Generate HTML report
	if err := tr.generateHTMLReport(); err != nil {
		return fmt.Errorf("failed to generate HTML report: %w", err)
	}

	// Print summary
	tr.printSummary()

	return nil
}

// generateJSONReport creates a JSON test report
func (tr *TestReporter) generateJSONReport() error {
	report := struct {
		Summary TestSummary  `json:"summary"`
		Results []TestResult `json:"results"`
	}{
		Summary: tr.Summary,
		Results: tr.Results,
	}

	data, err := json.MarshalIndent(report, "", "  ")
	if err != nil {
		return err
	}

	return os.WriteFile(tr.JSONPath, data, 0644)
}

// generateJUnitReport creates a JUnit XML report
func (tr *TestReporter) generateJUnitReport() error {
	// Convert our results to JUnit format
	suites := make(map[string][]TestResult)
	for _, result := range tr.Results {
		suites[result.Category] = append(suites[result.Category], result)
	}

	// Use Ginkgo's JUnit reporter as a base and adapt it
	_ = reporters.NewJUnitReporter(tr.JUnitPath)

	// Create a fake Ginkgo spec summary to leverage existing JUnit generation
	for category, results := range suites {
		for _, result := range results {
			spec := types.SpecSummary{
				ComponentTexts: []string{category, result.Name},
				State:          tr.convertStatusToGinkgoState(result.Status),
				RunTime:        result.Duration,
				Failure:        tr.createFailureIfNeeded(result),
			}

			// This is a simplified approach - in practice, you'd want to create
			// a proper JUnit XML structure
			_ = spec
		}
	}

	return nil
}

// generateHTMLReport creates an HTML test report
func (tr *TestReporter) generateHTMLReport() error {
	html := tr.generateHTMLContent()
	return os.WriteFile(tr.HTMLPath, []byte(html), 0644)
}

// generateHTMLContent creates HTML content for the test report
func (tr *TestReporter) generateHTMLContent() string {
	return fmt.Sprintf(`
<!DOCTYPE html>
<html>
<head>
    <title>O-RAN Intent-MANO Test Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .header { background-color: #f0f0f0; padding: 20px; border-radius: 5px; }
        .summary { margin: 20px 0; }
        .metric { display: inline-block; margin: 10px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; }
        .passed { background-color: #d4edda; }
        .failed { background-color: #f8d7da; }
        .skipped { background-color: #fff3cd; }
        .results { margin-top: 30px; }
        .result { margin: 10px 0; padding: 10px; border-left: 4px solid #ccc; }
        .result.passed { border-left-color: #28a745; }
        .result.failed { border-left-color: #dc3545; }
        .result.skipped { border-left-color: #ffc107; }
        .performance { margin-top: 30px; background-color: #e9ecef; padding: 20px; border-radius: 5px; }
        .threshold-met { color: #28a745; font-weight: bold; }
        .threshold-failed { color: #dc3545; font-weight: bold; }
    </style>
</head>
<body>
    <div class="header">
        <h1>O-RAN Intent-MANO Test Report</h1>
        <p>Generated: %s</p>
        <p>Duration: %v</p>
    </div>

    <div class="summary">
        <h2>Test Summary</h2>
        <div class="metric passed">Passed: %d</div>
        <div class="metric failed">Failed: %d</div>
        <div class="metric skipped">Skipped: %d</div>
        <div class="metric">Total: %d</div>
        <div class="metric">Success Rate: %.1f%%</div>
        <div class="metric">Coverage: %.1f%%</div>
    </div>

    <div class="performance">
        <h2>Performance Metrics</h2>
        %s
    </div>

    <div class="results">
        <h2>Test Results by Category</h2>
        %s
    </div>

    <div class="thresholds">
        <h2>Threshold Validation</h2>
        <p class="%s">Thresholds Met: %t</p>
        %s
    </div>
</body>
</html>`,
		tr.Summary.EndTime.Format(time.RFC3339),
		tr.Summary.Duration,
		tr.Summary.PassedTests,
		tr.Summary.FailedTests,
		tr.Summary.SkippedTests,
		tr.Summary.TotalTests,
		tr.Summary.SuccessRate,
		tr.Summary.Coverage,
		tr.generatePerformanceHTML(),
		tr.generateResultsHTML(),
		map[bool]string{true: "threshold-met", false: "threshold-failed"}[tr.Summary.ThresholdsMet],
		tr.Summary.ThresholdsMet,
		tr.generateThresholdsHTML(),
	)
}

// generatePerformanceHTML creates HTML for performance metrics
func (tr *TestReporter) generatePerformanceHTML() string {
	if tr.Summary.Performance == nil {
		return "<p>No performance data available</p>"
	}

	perf := tr.Summary.Performance
	return fmt.Sprintf(`
        <div class="metric">Deployment Time: %v</div>
        <div class="metric">Throughput: %.2f Mbps</div>
        <div class="metric">Latency: %.2f ms</div>
        <div class="metric">CPU Usage: %.1f%%</div>
        <div class="metric">Memory Usage: %.1f MB</div>
        <div class="metric">Error Rate: %.2f%%</div>
        <div class="metric">99p Response Time: %v</div>
        <div class="metric">RPS: %.1f</div>
    `,
		perf.DeploymentTime,
		perf.ThroughputMbps,
		perf.LatencyMs,
		perf.CPUUsage,
		perf.MemoryUsageMB,
		perf.ErrorRate,
		perf.ResponseTime99p,
		perf.RequestsPerSecond,
	)
}

// generateResultsHTML creates HTML for test results
func (tr *TestReporter) generateResultsHTML() string {
	html := ""
	for category, count := range tr.Summary.Categories {
		html += fmt.Sprintf("<h3>%s Tests (%d)</h3>\n", category, count)
		for _, result := range tr.Results {
			if result.Category == category {
				html += fmt.Sprintf(`
                <div class="result %s">
                    <strong>%s</strong> (%v)
                    %s
                </div>
                `, result.Status, result.Name, result.Duration,
					map[string]string{"failed": "<br>" + result.Error}[result.Status])
			}
		}
	}
	return html
}

// generateThresholdsHTML creates HTML for threshold validation
func (tr *TestReporter) generateThresholdsHTML() string {
	html := "<ul>"
	for key, value := range tr.Summary.Thresholds {
		status := "‚úÖ"
		switch key {
		case "coverage_threshold":
			if tr.Summary.Coverage < value.(float64) {
				status = "‚ùå"
			}
		case "success_rate_threshold":
			if tr.Summary.SuccessRate < value.(float64) {
				status = "‚ùå"
			}
		}
		html += fmt.Sprintf("<li>%s %s: %v</li>", status, key, value)
	}
	html += "</ul>"
	return html
}

// checkThresholds validates if performance thresholds are met
func (tr *TestReporter) checkThresholds() {
	tr.Summary.ThresholdsMet = true

	// Check coverage threshold
	if tr.Summary.Coverage < tr.Summary.Thresholds["coverage_threshold"].(float64) {
		tr.Summary.ThresholdsMet = false
	}

	// Check success rate threshold
	if tr.Summary.SuccessRate < tr.Summary.Thresholds["success_rate_threshold"].(float64) {
		tr.Summary.ThresholdsMet = false
	}

	// Check performance thresholds if available
	if tr.Summary.Performance != nil {
		if tr.Summary.Performance.DeploymentTime.Seconds() > float64(tr.Summary.Thresholds["max_deployment_time_s"].(int)) {
			tr.Summary.ThresholdsMet = false
		}
		if tr.Summary.Performance.ThroughputMbps < tr.Summary.Thresholds["min_throughput_mbps"].(float64) {
			tr.Summary.ThresholdsMet = false
		}
		if tr.Summary.Performance.LatencyMs > tr.Summary.Thresholds["max_latency_ms"].(float64) {
			tr.Summary.ThresholdsMet = false
		}
	}
}

// printSummary prints a test summary to console
func (tr *TestReporter) printSummary() {
	fmt.Println("\n" + strings.Repeat("=", 60))
	fmt.Println("üìä TEST EXECUTION SUMMARY")
	fmt.Println(strings.Repeat("=", 60))
	fmt.Printf("‚è±Ô∏è  Duration: %v\n", tr.Summary.Duration)
	fmt.Printf("üìà Total Tests: %d\n", tr.Summary.TotalTests)
	fmt.Printf("‚úÖ Passed: %d\n", tr.Summary.PassedTests)
	fmt.Printf("‚ùå Failed: %d\n", tr.Summary.FailedTests)
	fmt.Printf("‚è≠Ô∏è  Skipped: %d\n", tr.Summary.SkippedTests)
	fmt.Printf("üìä Success Rate: %.1f%%\n", tr.Summary.SuccessRate)
	fmt.Printf("üéØ Coverage: %.1f%%\n", tr.Summary.Coverage)

	if tr.Summary.Performance != nil {
		fmt.Println("\nüìã PERFORMANCE METRICS")
		fmt.Println(strings.Repeat("-", 30))
		fmt.Printf("üöÄ Deployment Time: %v\n", tr.Summary.Performance.DeploymentTime)
		fmt.Printf("üì° Throughput: %.2f Mbps\n", tr.Summary.Performance.ThroughputMbps)
		fmt.Printf("‚ö° Latency: %.2f ms\n", tr.Summary.Performance.LatencyMs)
		fmt.Printf("üî• CPU Usage: %.1f%%\n", tr.Summary.Performance.CPUUsage)
		fmt.Printf("üíæ Memory Usage: %.1f MB\n", tr.Summary.Performance.MemoryUsageMB)
	}

	fmt.Println("\nüéØ THRESHOLD VALIDATION")
	fmt.Println(strings.Repeat("-", 30))
	if tr.Summary.ThresholdsMet {
		fmt.Println("‚úÖ All thresholds met!")
	} else {
		fmt.Println("‚ùå Some thresholds not met!")
	}

	fmt.Printf("\nüìÑ Reports generated in: %s\n", tr.OutputDir)
	fmt.Println(strings.Repeat("=", 60))
}

// Helper methods
func (tr *TestReporter) convertStatusToGinkgoState(status string) types.SpecState {
	switch status {
	case "passed":
		return types.SpecStatePassed
	case "failed":
		return types.SpecStateFailed
	case "skipped":
		return types.SpecStateSkipped
	default:
		return types.SpecStatePending
	}
}

func (tr *TestReporter) createFailureIfNeeded(result TestResult) types.Failure {
	if result.Status == "failed" {
		return types.Failure{
			Message: result.Error,
		}
	}
	return types.Failure{}
}

// UpdatePerformanceMetrics updates the performance metrics in the summary
func (tr *TestReporter) UpdatePerformanceMetrics(metrics *PerformanceMetrics) {
	tr.Summary.Performance = metrics
}

// SetCoverage sets the code coverage percentage
func (tr *TestReporter) SetCoverage(coverage float64) {
	tr.Summary.Coverage = coverage
}